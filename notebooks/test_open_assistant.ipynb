{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11d39f8",
   "metadata": {},
   "source": [
    "# Open Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e655b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.k.avito.ru/pypi/\n",
      "Collecting torch==1.13.1\n",
      "  Downloading https://pypi.k.avito.ru/api/package/torch/torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading https://pypi.k.avito.ru/api/package/nvidia-cublas-cu11/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading https://pypi.k.avito.ru/api/package/nvidia-cudnn-cu11/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading https://pypi.k.avito.ru/api/package/nvidia-cuda-runtime-cu11/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading https://pypi.k.avito.ru/api/package/nvidia-cuda-nvrtc-cu11/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch==1.13.1) (4.4.0)\n",
      "Collecting wheel\n",
      "  Downloading https://pypi.k.avito.ru/api/package/wheel/wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (58.1.0)\n",
      "Installing collected packages: wheel, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "\u001b[33m  WARNING: The script wheel is installed in '/home/avzelentsov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/avzelentsov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 wheel-0.40.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60c78f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.k.avito.ru/pypi/\n",
      "Obtaining file:///archive/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (0.13.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers==4.28.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.28.0.dev0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.28.0.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building editable for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.28.0.dev0-0.editable-py3-none-any.whl size=35154 sha256=aeb321f056661ef92aa9b6bb54ba9f747f21c6da03970710c3dae25c639d4f1c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5_rw1nyj/wheels/53/d7/1b/8766a104990dfa7d49c170934f640afb9f2a690369b73abc09\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/avzelentsov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed transformers-4.28.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!cd transformers && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f8f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.k.avito.ru/pypi/\n",
      "Collecting accelerate\n",
      "  Downloading https://pypi.k.avito.ru/api/package/accelerate/accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading https://pypi.k.avito.ru/api/package/bitsandbytes/bitsandbytes-0.37.2-py3-none-any.whl (84.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/avzelentsov/.local/lib/python3.9/site-packages (from accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/avzelentsov/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/avzelentsov/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/avzelentsov/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/avzelentsov/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/avzelentsov/.local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (58.1.0)\n",
      "Installing collected packages: bitsandbytes, accelerate\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/home/avzelentsov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-0.18.0 bitsandbytes-0.37.2\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0c64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae35142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.28.0.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1164bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e23674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22a04c435544b26ad097e57ac210983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76809045449c4ce6be299736ed39e5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/47.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea9002d71c642fe8174d6110236b4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b562a7cde942410e93ea4b993e14f20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)00001-of-00003.bin\";:   0%|          | 0.00/9.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"OpenAssistant/oasst-sft-1-pythia-12b\", cache_dir=\"/archive/transformers_cache/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2847bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"OpenAssistant/oasst-sft-1-pythia-12b\",\n",
    "   cache_dir=\"/archive/transformers_cache/\",\n",
    "   padding_side='left',\n",
    "   max_length = 100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0759c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c0a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  3 22:22:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    69W / 300W |  48298MiB / 81920MiB |     22%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    47W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    43W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    43W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     17394      C                                    2009MiB |\n",
      "|    0   N/A  N/A     51848      C                                   46287MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90dd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, I am\", return_tensors=\"pt\")\n",
    "for key in inputs:\n",
    "    inputs[key] = inputs[key].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df88b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/usr/local/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, I am Open Assistant. Is there anything I can help you with?<|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs = tokenizer(\"Hello, I am\", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs)\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19596756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_open_assistant(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].cuda()\n",
    "    tokens = model.generate(**inputs, max_length=100000)\n",
    "    return tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_open_assistant(prompt):\n",
    "    while not prompt.endswith(\"<|endoftext|>\"):\n",
    "        prompt = gen_one_open_assistant(prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004a455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(prompt):\n",
    "    res = gen_open_assistant(\"<|prompter|>\" + prompt + \"<|endoftext|><|assistant|>\")\n",
    "    print(\"PROMPT\")\n",
    "    print(prompt)\n",
    "    print()\n",
    "    print(\"ANSWER\")\n",
    "    print(res.split(\"<|endoftext|><|assistant|>\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "368f2620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Tell me a list of topics related to interior design\n",
      "\n",
      "ANSWER\n",
      "Interior design is the art and science of creating the interior environment of a building or space. It involves the selection, arrangement, and modification of interior elements such as furniture, walls, and lighting to create a comfortable, functional, and aesthetically pleasing space. Here are some related topics:\n",
      "\n",
      "Interior design principles: These include space planning, color theory, texture, and lighting design.\n",
      "\n",
      "Design trends: These include minimalism, modernism, and traditionalism.\n",
      "\n",
      "Materials and finishes: This includes the use of natural materials, such as wood, stone, and ceramics, as well as more modern materials such as metal, plastic, and glass.\n",
      "\n",
      "Spatial planning: This involves the arrangement of rooms and spaces to create a functional and efficient layout.\n",
      "\n",
      "Lighting design: This involves the selection of appropriate lighting sources, including natural light, artificial light, and LED lighting, to create a comfortable and well-lit space.\n",
      "\n",
      "Decorating styles: This includes traditional, modern, and minimalist decorating styles.\n",
      "\n",
      "Interior design techniques: These include color consulting, furniture selection, and space planning.\n",
      "\n",
      "Project management: This involves the coordination of the design process, including the selection of materials, finishes, and contractors.\n",
      "\n",
      "These are just a few of the many topics related to interior design. If you have any specific questions or would like to learn more, feel free to ask!<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Tell me a list of topics related to interior design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "172fce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "What is a meme, and what's the history behind this word?\n",
      "\n",
      "ANSWER\n",
      "The word \"meme\" was first used in the 1960s by Richard Dawkins to describe an idea, behavior, or style that is transmitted from one individual to another within a culture. The concept of a meme was later popularized by internet culture, where the term has taken on a new meaning to describe images, videos, or other forms of content that are shared and altered by users.\n",
      "\n",
      "The history of the word \"meme\" dates back to the ancient Greek philosopher Aristotle, who used the term \"mimeme\" to describe an idea that was passed from one person to another. The concept of a mimeme was later adopted by the Romans, who used the term \"imitation\" to describe the process of transmitting ideas and behaviors from one generation to another.\n",
      "\n",
      "The use of the term \"meme\" in internet culture has become increasingly popular over the last few decades, and it has been used to describe everything from viral videos to political memes to social media trends. The concept of the meme has become an important part of modern culture, and it continues to evolve and evolve as new forms of content are created and shared online.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"What is a meme, and what's the history behind this word?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8e972a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "The name of the next Star Wars movie is\n",
      "\n",
      "ANSWER\n",
      "The name of the next Star Wars movie is Star Wars: The Rise of Skywalker.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"The name of the next Star Wars movie is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36f3a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "\n",
      "When you drop a heavy stone from a tree, what happens?\n",
      "A. The stone falls to the ground.\n",
      "B: The stone stays in the tree.\n",
      "C: The stone floats.\n",
      "D: Nothing happens.\n",
      "\n",
      "\n",
      "ANSWER\n",
      "The correct answer is: **\"A. The stone falls to the ground.\"**\n",
      "\n",
      "The reason is that when you drop a heavy stone from a tree, the force of gravity acting on it is strong enough to overcome the force of the branch or the tree itself, causing the stone to fall to the ground. The stone may also strike the ground with a loud noise, depending on the size and weight of the stone.\n",
      "\n",
      "In contrast, if the stone was too light or if the branch or tree was too strong, the stone may stay in the tree or may float in the air. This is known as **\"buoyancy\"**, which is the tendency of objects to float or rise in a fluid such as water or air.\n",
      "\n",
      "Therefore, when you drop a heavy stone from a tree, the stone will fall to the ground because the force of gravity is stronger than the force of the branch or the tree itself.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "When you drop a heavy stone from a tree, what happens?\n",
    "A. The stone falls to the ground.\n",
    "B: The stone stays in the tree.\n",
    "C: The stone floats.\n",
    "D: Nothing happens.\n",
    "\"\"\"\n",
    "\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e709add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Who is Batman?\n",
      "\n",
      "ANSWER\n",
      "Batman is a fictional character created by artist Bob Kane and writer Bill Finger for the DC Comics publishing company. Batman first appeared in the comic book series \"Detective Comics\" in 1939 and has since become one of the most well-known and beloved characters in the DC Universe. Batman is a skilled detective, trained in the use of various weapons and gadgets, and is always willing to put his life on the line to protect the people of Gotham City. He is known for his intelligence, cunning, and physical abilities, and is often depicted as a symbol of justice and morality in the DC Universe.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Who is Batman?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fdae0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Give students tips on how to keep their nerves under control during class presentations.\n",
      "\n",
      "ANSWER\n",
      "Here are some tips to help students keep their nerves under control during class presentations:\n",
      "\n",
      "1. Practice your presentation: Before your presentation, practice it with a friend or classmate to get feedback and identify any areas that need improvement.\n",
      "\n",
      "2. Focus on the content: Instead of worrying about your nerves, focus on the content of your presentation. Take time to understand the material and practice your delivery.\n",
      "\n",
      "3. Use visual aids: Use visual aids such as PowerPoint, Keynote, or Prezi to help you organize your thoughts and present your information in a clear and concise manner.\n",
      "\n",
      "4. Stay calm and confident: Try to stay calm and confident during your presentation. If you feel nervous, take a few deep breaths and focus on your message.\n",
      "\n",
      "5. Ask for feedback: After your presentation, ask your classmates for feedback. This can help you identify areas for improvement and make your presentation even better.\n",
      "\n",
      "6. Stay hydrated: Drinking plenty of water before and during your presentation can help you stay focused and energized.\n",
      "\n",
      "Remember, the key to keeping your nerves under control is to be prepared and confident in your presentation. With practice and a little bit of nerves, you'll be ready to deliver a great presentation!<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Give students tips on how to keep their nerves under control during class presentations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "113f796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "\n",
      "The following is a list of companies and the categories they fall into:\n",
      "Apple, Facebook, Fedex\n",
      "\n",
      "Apple\n",
      "Category: Technology\n",
      "\n",
      "Facebook\n",
      "Category: Social Media\n",
      "\n",
      "Fedex\n",
      "Category:\n",
      "\n",
      "\n",
      "ANSWER\n",
      "I'm sorry, but I don't have specific information about each company. However, I can provide you with general information about each category.\n",
      "\n",
      "Technology:\n",
      "\n",
      "- Apple is a technology company that specializes in the design, development, and marketing of consumer electronics, such as smartphones, laptops, and tablets.\n",
      "- Facebook is a social media platform that allows people to connect, share information, and engage in conversations with others.\n",
      "- Fedex is a global delivery company that provides a range of logistics services, including package delivery, air cargo, and logistics consulting.\n",
      "\n",
      "Social Media:\n",
      "\n",
      "- Facebook is a social media platform that allows people to connect, share information, and engage in conversations with others.\n",
      "- Instagram is a social media platform that allows people to share photos and videos with others.\n",
      "- Twitter is a social media platform that allows people to share short messages, links, and other content.\n",
      "\n",
      "Logistics:\n",
      "\n",
      "- Fedex is a global delivery company that provides a range of logistics services, including package delivery, air cargo, and logistics consulting.\n",
      "- DHL is a global delivery company that provides a range of logistics services, including package delivery, air cargo, and logistics consulting.\n",
      "- logistics software is software that is used to manage logistics operations, such as order fulfillment, inventory management, and transportation planning.\n",
      "\n",
      "I hope this information is helpful. If you have any other questions, please let me know.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "The following is a list of companies and the categories they fall into:\n",
    "Apple, Facebook, Fedex\n",
    "\n",
    "Apple\n",
    "Category: Technology\n",
    "\n",
    "Facebook\n",
    "Category: Social Media\n",
    "\n",
    "Fedex\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b772b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I really like to play Counter Strike\n",
      "\n",
      "ANSWER\n",
      "I'm sorry, but I am not able to play Counter Strike. I am a language model trained to respond to a variety of questions and generate text on a wide range of topics. While I can understand and process text, I do not have the ability to execute commands or play video games.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I really like to play Counter Strike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e02368b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Summarize the following dialogue in 3 sentences:\n",
      "Jules: Hey kids! How you boys doin’?\n",
      "Jules: (Speaking to the guy laying on the couch) Hey, keep chillin’. You know who we are? We’re associates of your business partner Marsellus Wallace. You do remember your business partner don’t you? Let me take a wild guess here. You’re Brett, right?\n",
      "Brett: Yeah.\n",
      "Jules: I thought so. You remember your business partner Marsellus Wallace, don’t you, Brett?\n",
      "Brett: Yeah, yeah, I remember him.\n",
      "Jules: Good. Looks like me an Vincent caught you boys at breakfast. Sorry about that. Whatcha havin’?\n",
      "Brett: Hamburgers.\n",
      "Jules: Hamburgers! The cornerstone of any nutritious breakfast. What kind of hamburgers?\n",
      "Brett: Ch-cheeseburgers.\n",
      "Jules: No, no no, where’d you get ’em? McDonalds? Wendy’s? Jack in the Box? Where?\n",
      "Brett: Big Kahuna Burger.\n",
      "Jules: Big Kahuna Burger. That’s that Hawaiian burger joint. I hear they got some tasty burgers. I ain’t never had one myself. How are they?\n",
      "Brett: They’re good.\n",
      "Jules: Mind if I try one of yours? This is yours here, right?\n",
      "Jules: (Picks up burger and takes a bite) Mmm-mmmm. That is a tasty burger. Vincent, ever have a Big Kahuna Burger?\n",
      "(Vincent shakes his head)\n",
      "Jules: Wanna bite? They’re real tasty.\n",
      "Vincent: Ain’t hungry.\n",
      "\n",
      "ANSWER\n",
      "Jules: Hey kids! How you boys doin’?\n",
      "Brett: (Laying on couch) Hey, keep chillin’. You know who we are? We’re associates of your business partner Marsellus Wallace. You do remember your business partner don’t you? Let me take a wild guess here. You’re Brett, right?\n",
      "Jules: (To Brett) Yeah, I thought so. You remember your business partner Marsellus Wallace, don’t you, Brett?\n",
      "Brett: Yeah, I remember him.\n",
      "Jules: Good.Looks like me an Vincent caught you boys at breakfast. Sorry about that. Whatcha havin’?\n",
      "Brett: Hamburgers.\n",
      "Jules: Hamburgers! The cornerstone of any nutritious breakfast. What kind of hamburgers?\n",
      "Brett: Ch-cheeseburgers.\n",
      "Jules: No, no no, where’d you get them? McDonalds? Wendy’s? Jack in the Box? Where?\n",
      "Brett: Big Kahuna Burger.\n",
      "Jules: Big Kahuna Burger. That’s that Hawaiian burger joint. I hear they got some tasty burgers. I ain’t never had one myself. How are they?\n",
      "Brett: They’re good.\n",
      "Jules: Mind if I try one of yours? This is yours here, right?\n",
      "Brett: (Picks up burger and takes a bite) Mmm-mmmm. That is a tasty burger. Vincent, ever have a Big Kahuna Burger?\n",
      "Vincent: (Shakes his head) Ain’t hungry.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Summarize the following dialogue in 3 sentences:\n",
    "Jules: Hey kids! How you boys doin’?\n",
    "Jules: (Speaking to the guy laying on the couch) Hey, keep chillin’. You know who we are? We’re associates of your business partner Marsellus Wallace. You do remember your business partner don’t you? Let me take a wild guess here. You’re Brett, right?\n",
    "Brett: Yeah.\n",
    "Jules: I thought so. You remember your business partner Marsellus Wallace, don’t you, Brett?\n",
    "Brett: Yeah, yeah, I remember him.\n",
    "Jules: Good. Looks like me an Vincent caught you boys at breakfast. Sorry about that. Whatcha havin’?\n",
    "Brett: Hamburgers.\n",
    "Jules: Hamburgers! The cornerstone of any nutritious breakfast. What kind of hamburgers?\n",
    "Brett: Ch-cheeseburgers.\n",
    "Jules: No, no no, where’d you get ’em? McDonalds? Wendy’s? Jack in the Box? Where?\n",
    "Brett: Big Kahuna Burger.\n",
    "Jules: Big Kahuna Burger. That’s that Hawaiian burger joint. I hear they got some tasty burgers. I ain’t never had one myself. How are they?\n",
    "Brett: They’re good.\n",
    "Jules: Mind if I try one of yours? This is yours here, right?\n",
    "Jules: (Picks up burger and takes a bite) Mmm-mmmm. That is a tasty burger. Vincent, ever have a Big Kahuna Burger?\n",
    "(Vincent shakes his head)\n",
    "Jules: Wanna bite? They’re real tasty.\n",
    "Vincent: Ain’t hungry.\"\"\"\n",
    "\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13a66ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I am making a presentation about you. Suggest an outline for the presentation\n",
      "\n",
      "ANSWER\n",
      "Sure, here's an outline for your presentation about me:\n",
      "\n",
      "I. Introduction\n",
      "A. Who is presenting?\n",
      "B. What is the purpose of the presentation?\n",
      "C. The audience for the presentation\n",
      "\n",
      "II. My Background\n",
      "A. My education and experience\n",
      "B. My areas of expertise\n",
      "C. My leadership experience\n",
      "\n",
      "III. My Skills and Expertise\n",
      "A. My technical skills and expertise\n",
      "B. My communication skills and expertise\n",
      "C. My problem-solving skills and expertise\n",
      "\n",
      "IV. My Approach to Work\n",
      "A. My work style and approach\n",
      "B. My strengths and weaknesses as a leader\n",
      "C. My approach to innovation and creativity\n",
      "\n",
      "V. My Community Involvement\n",
      "A. My volunteer work and community involvement\n",
      "B. My leadership roles in my community\n",
      "C. My impact on my community and the world at large\n",
      "\n",
      "VI. My Future Goals and Aspirations\n",
      "A. My career goals and aspirations\n",
      "B. My vision for the future of my organization\n",
      "C. My hopes and dreams for the future of the world<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I am making a presentation about you. Suggest an outline for the presentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61c07eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I am making a presentation about Open Assistant. Suggest an outline for the presentation\n",
      "\n",
      "ANSWER\n",
      "Here is an outline for your presentation about Open Assistant:\n",
      "\n",
      "I. Introduction\n",
      "A. Definition of Open Assistant\n",
      "B. Importance of Open Assistant\n",
      "C. Thesis statement: Open Assistant will change the world for the better\n",
      "\n",
      "II. The Problem with AI\n",
      "A. Lack of transparency\n",
      "B. Lack of accountability\n",
      "C. Lack of privacy\n",
      "\n",
      "III. The Benefits of Open AI\n",
      "A. Transparency\n",
      "B. Accountability\n",
      "C. Privacy\n",
      "\n",
      "IV. The Different Types of Open AI\n",
      "A. Open Source AI\n",
      "B. Commercial AI\n",
      "C. Hybrid AI\n",
      "\n",
      "V. The Challenges of Open AI\n",
      "A. Scalability\n",
      "B. Interoperability\n",
      "C. Security\n",
      "\n",
      "VI. Conclusion\n",
      "A. Summary of the presentation\n",
      "B. Call to action for individuals to support Open AI\n",
      "C. Thank you for your time and consideration.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I am making a presentation about Open Assistant. Suggest an outline for the presentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8b246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "What do you think about Black Lives Matter movement?\n",
      "\n",
      "ANSWER\n",
      "As an AI chat assistant, I don't have personal opinions or beliefs. However, I can provide you with information and resources on the Black Lives Matter movement.\n",
      "\n",
      "Black Lives Matter is a social justice movement that aims to end police brutality and discrimination against African Americans. The movement has gained momentum in recent years, with protests and demonstrations taking place across the country.\n",
      "\n",
      "Black Lives Matter activists have made a number of demands, including the implementation of police reform measures, the end of racial profiling and discrimination in all areas of life, and the prosecution of those who commit crimes against African Americans.\n",
      "\n",
      "The movement has been met with opposition from some members of the community, who argue that the focus on police brutality and discrimination is not enough and that other issues, such as poverty and inequality, also need to be addressed.\n",
      "\n",
      "It's important to note that the Black Lives Matter movement is a complex and multifaceted issue that requires ongoing attention and action. While there have been positive steps taken in recent years, there is still much work to be done to achieve true racial equality and justice.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"What do you think about Black Lives Matter movement?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256918b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Write an e-mail to congratulate new Skoltech admits and mention that you are exitedabout meeting all of them inperson.\n",
      "\n",
      "ANSWER\n",
      "Subject: Congratulations to Our New Skoltech Admissions!\n",
      "\n",
      "Dear [New Admissions Name],\n",
      "\n",
      "We are writing to extend our warmest welcome to you and your family as you begin your journey at Skoltech. We are excited to have you join our community and look forward to helping you grow and thrive in this innovative and forward-looking educational environment.\n",
      "\n",
      "We understand that the decision to pursue a higher education degree can be a significant one, and we are committed to assisting you in making the best choice for your future. Our team of admissions experts is here to guide you through the application process, answer any questions you may have, and provide you with personalized support throughout the journey.\n",
      "\n",
      "We are confident that you will find the education and experiences at Skoltech to be both challenging and rewarding. Our students are known for their creativity, innovation, and problem-solving skills, and we are committed to helping them develop these skills and apply them to real-world problems.\n",
      "\n",
      "We look forward to the opportunity to get to know you and welcome you to the Skoltech community. If you have any questions or would like to schedule a visit, please do not hesitate to reach out.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Write an e-mail to congratulate new Skoltech admits and mention that you are exited\"\n",
    "       \"about meeting all of them inperson.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b40c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Explain how language models are trained to 5 years old child\n",
      "\n",
      "ANSWER\n",
      "A language model is a computer program that is trained to predict the next word in a sequence of text. This training process involves inputting a large amount of text into the model and adjusting its parameters to make it produce more accurate predictions.\n",
      "\n",
      "When a child is learning a new language, they are exposed to a large amount of language input over a period of time. This input is used to train the language model to recognize patterns in the language and generate predictions.\n",
      "\n",
      "The language model is trained on the input data by comparing the predicted next word with the actual next word in the sequence. This process is called reinforcement learning, as the model is rewarded or punished based on its accuracy. The model is trained to make accurate predictions over many iterations, so that it can begin to understand the structure of the language and generate coherent and meaningful responses.\n",
      "\n",
      "As the child continues to learn the language, the language model can be used to provide feedback and help them improve their pronunciation, grammar, and vocabulary. The language model can also be used to create language-based games and other interactive tools that help children practice their language skills.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Explain how language models are trained to 5 years old child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26be4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Who is Donald Trump?\n",
      "\n",
      "ANSWER\n",
      "Donald Trump is an American businessman and politician who is the 45th and current President of the United States. He was elected on November 8, 2016, and took office on January 20, 2017. He previously served as the President of the United States from 2009 to 2017.\n",
      "\n",
      "Before becoming President, Trump was a businessman and reality television star. He founded the Trump Organization in 1980 and built it into one of the world's largest real estate development and management companies. He also launched several successful television shows, including \"The Apprentice\" and \"The Miss USA Pageant.\"\n",
      "\n",
      "In politics, Trump has been a controversial figure, with his policies and statements drawing criticism from both Republicans and Democrats. He has been accused of being divisive, Islamophobic, and misogynistic, and has been criticized for his handling of several domestic and international issues, including the COVID-19 pandemic, the economy, and foreign policy.\n",
      "\n",
      "Despite these challenges, Trump has been able to maintain a strong base of support among Republicans and has been able to win several elections, including the 2016 presidential election. He remains a major figure in American politics and is expected to be a major player in the 2020 presidential election.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Who is Donald Trump?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a0ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
