{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11d39f8",
   "metadata": {},
   "source": [
    "# BLOOMZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "876dfbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/bin/sh: 1: git: not found\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/s-nlp/filimdb_evaluation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0c64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9faf4f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.28.0.dev0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1164bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b68bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/archive/llm_test/transformers/src/transformers']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90d8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__path__\n"
     ]
    }
   ],
   "source": [
    "for d in dir(transformers):\n",
    "    if \"path\" in d:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19e23674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f07f0e076d48e58ac7e5bbca3f7dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2655b017f2be497da8253ccecf6d42d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/14.1G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-7b1-mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dbbd255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomForCausalLM(\n",
       "  (transformer): BloomModel(\n",
       "    (word_embeddings): Embedding(250880, 4096)\n",
       "    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (h): ModuleList(\n",
       "      (0-29): 30 x BloomBlock(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): BloomAttention(\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): BloomMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (gelu_impl): BloomGelu()\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2847bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66331fb12eb7477485161526173acc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/199 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73635020fc84fa9a6bf8c72e5f57c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tokenizer.json\";:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83ff802267146c7b8b100a86706c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"bigscience/bloomz-7b1-mt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f794cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0759c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c0a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Tue Apr 11 08:33:37 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    65W / 300W |  31690MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    70W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    60W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    43W / 300W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     21117      C                                   27809MiB |\n",
      "|    0   N/A  N/A     61793      C                                    3879MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f58bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(inputs, max_length=100)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c02a0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "eliades => элиадис\n",
    "timergazin => тимергазин\n",
    "tecklenburg => текленбург\n",
    "tirico =>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea9f4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eliades => элиадис\n",
      "timergazin => тимергазин\n",
      "tecklenburg => текленбург\n",
      "tirico =>\n",
      "titanic => тайнтик</s>\n"
     ]
    }
   ],
   "source": [
    "print(gen(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "004a455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(instruction, input_ctxt):\n",
    "    res = gen(instruction, input_ctxt)\n",
    "    print(\"PROMPT\")\n",
    "    print(instruction)\n",
    "    print(input_ctxt)\n",
    "    print()\n",
    "    print(\"ANSWER\")\n",
    "    print(res.split(\"### Response:\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e972a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "The name of the next Star Wars movie is\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "The name of the next Star Wars movie is Star Wars: The Rise of Skywalker.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"The name of the next Star Wars movie is\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "368f2620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Tell me a list of topics related to interior design\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "1. Furniture arrangement\n",
      "2. Color schemes\n",
      "3. Lighting design\n",
      "4. Texture and pattern\n",
      "5. Space planning\n",
      "6. Art and decor\n",
      "7. Storage solutions\n",
      "8. Window treatments\n",
      "9. Flooring options\n",
      "10. Cleaning and maintenance\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Tell me a list of topics related to interior design\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "172fce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "What is a meme, and what's the history behind this word?\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "A meme is an idea, behavior, or activity that spreads from person to person, often related to humor or culture. The word \"meme\" was first used in 1976 by evolutionary biologist Richard Dawkins to describe a unit of cultural information that can spread from person to person. The concept has since been used to describe ideas, images, or videos that spread quickly online, often with a humorous or satirical tone.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"What is a meme, and what's the history behind this word?\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f3a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "\n",
      "When you drop a heavy stone from a tree, what happens?\n",
      "A. The stone falls to the ground.\n",
      "B: The stone stays in the tree.\n",
      "C: The stone floats.\n",
      "D: Nothing happens.\n",
      "\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "A. The stone falls to the ground.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "When you drop a heavy stone from a tree, what happens?\n",
    "A. The stone falls to the ground.\n",
    "B: The stone stays in the tree.\n",
    "C: The stone floats.\n",
    "D: Nothing happens.\n",
    "\"\"\"\n",
    "\n",
    "pprint(text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e709add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Who is Batman?\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Batman is a fictional superhero who appears in comic books, movies, and other media. He is a vigilante who fights crime in Gotham City using his martial arts skills, detective skills, and technological gadgets. He is often allied with other superheroes such as Superman and Wonder Woman.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Who is Batman?\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fdae0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Give students tips on how to keep their nerves under control during class presentations.\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Students should practice presenting their work ahead of time and be familiar with the material they are presenting. They should also take deep breaths and focus on their own body language to remain calm and confident. Additionally, they should make sure to maintain eye contact with the audience and speak at a slow and clear pace.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Give students tips on how to keep their nerves under control during class presentations.\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "113f796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "\n",
      "The following is a list of companies and the categories they fall into:\n",
      "Apple, Facebook, Fedex\n",
      "\n",
      "Apple\n",
      "Category: Technology\n",
      "\n",
      "Facebook\n",
      "Category: Social Media\n",
      "\n",
      "Fedex\n",
      "Category:\n",
      "\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Apple: Technology\n",
      "\n",
      "Facebook: Social Media\n",
      "\n",
      "Fedex: Logistics\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "The following is a list of companies and the categories they fall into:\n",
    "Apple, Facebook, Fedex\n",
    "\n",
    "Apple\n",
    "Category: Technology\n",
    "\n",
    "Facebook\n",
    "Category: Social Media\n",
    "\n",
    "Fedex\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "pprint(text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b772b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I really like to play Counter Strike\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Me too! What is your favorite map?\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I really like to play Counter Strike\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e02368b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Summarize the following dialogue in 3 sentences:\n",
      "\n",
      "Jules: Hey kids! How you boys doin’?\n",
      "Jules: (Speaking to the guy laying on the couch) Hey, keep chillin’.\n",
      "You know who we are? We’re associates of your business partner Marsellus Wallace.\n",
      "You do remember your business partner don’t you? Let me take a wild guess here. You’re Brett, right?\n",
      "Brett: Yeah.\n",
      "Jules: I thought so. You remember your business partner Marsellus Wallace, don’t you, Brett?\n",
      "Brett: Yeah, yeah, I remember him.\n",
      "Jules: Good. Looks like me an Vincent caught you boys at breakfast. Sorry about that. Whatcha havin’?\n",
      "Brett: Hamburgers.\n",
      "Jules: Hamburgers! The cornerstone of any nutritious breakfast. What kind of hamburgers?\n",
      "Brett: Ch-cheeseburgers.\n",
      "Jules: No, no no, where’d you get ’em? McDonalds? Wendy’s? Jack in the Box? Where?\n",
      "Brett: Big Kahuna Burger.\n",
      "Jules: Big Kahuna Burger. That’s that Hawaiian burger joint. I hear they got some tasty burgers.\n",
      "I ain’t never had one myself. How are they?\n",
      "Brett: They’re good.\n",
      "Jules: Mind if I try one of yours? This is yours here, right?\n",
      "Jules: (Picks up burger and takes a bite) Mmm-mmmm. That is a tasty burger. Vincent, ever have a Big Kahuna Burger?\n",
      "(Vincent shakes his head)\n",
      "Jules: Wanna bite? They’re real tasty.\n",
      "Vincent: Ain’t hungry.\n",
      "\n",
      "\n",
      "ANSWER\n",
      "Jules and Vincent have just met Brett, who is Marsellus Wallace's business partner. Jules is friendly and asks how the boys are doing, then proceeds to ask Brett questions about his business partner. Jules and Vincent then notice that Brett is eating Big Kahuna Burgers and Jules offers to try one. Vincent declines, but Jules takes a bite and finds it to be delicious. Jules then offers Vincent a bite, but he declines.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Summarize the following dialogue in 3 sentences:\"\"\"\n",
    "ctx = \"\"\"\n",
    "Jules: Hey kids! How you boys doin’?\n",
    "Jules: (Speaking to the guy laying on the couch) Hey, keep chillin’.\n",
    "You know who we are? We’re associates of your business partner Marsellus Wallace.\n",
    "You do remember your business partner don’t you? Let me take a wild guess here. You’re Brett, right?\n",
    "Brett: Yeah.\n",
    "Jules: I thought so. You remember your business partner Marsellus Wallace, don’t you, Brett?\n",
    "Brett: Yeah, yeah, I remember him.\n",
    "Jules: Good. Looks like me an Vincent caught you boys at breakfast. Sorry about that. Whatcha havin’?\n",
    "Brett: Hamburgers.\n",
    "Jules: Hamburgers! The cornerstone of any nutritious breakfast. What kind of hamburgers?\n",
    "Brett: Ch-cheeseburgers.\n",
    "Jules: No, no no, where’d you get ’em? McDonalds? Wendy’s? Jack in the Box? Where?\n",
    "Brett: Big Kahuna Burger.\n",
    "Jules: Big Kahuna Burger. That’s that Hawaiian burger joint. I hear they got some tasty burgers.\n",
    "I ain’t never had one myself. How are they?\n",
    "Brett: They’re good.\n",
    "Jules: Mind if I try one of yours? This is yours here, right?\n",
    "Jules: (Picks up burger and takes a bite) Mmm-mmmm. That is a tasty burger. Vincent, ever have a Big Kahuna Burger?\n",
    "(Vincent shakes his head)\n",
    "Jules: Wanna bite? They’re real tasty.\n",
    "Vincent: Ain’t hungry.\n",
    "\"\"\"\n",
    "\n",
    "pprint(text, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13a66ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I am making a presentation about you. Suggest an outline for the presentation\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Outline for Presentation: \n",
      "\n",
      "I. Introduction \n",
      "A. Introduction of the Presenter \n",
      "B. Introduction of the Person Being Presented \n",
      "\n",
      "II. Body \n",
      "A. Personal Information \n",
      "B. Professional Information \n",
      "C. Accomplishments \n",
      "\n",
      "III. Conclusion \n",
      "A. Closing Remarks \n",
      "B. Final Words of Advice\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I am making a presentation about you. Suggest an outline for the presentation\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61c07eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "I am making a presentation about ALPACA language model. Suggest an outline for the presentation\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Outline for ALPACA Language Model Presentation:\n",
      "\n",
      "I. Introduction \n",
      "A. Definition of ALPACA \n",
      "B. Advantages of ALPACA \n",
      "\n",
      "II. History \n",
      "A. Development of ALPACA \n",
      "B. Evolution of ALPACA \n",
      "\n",
      "III. Applications \n",
      "A. Natural Language Processing \n",
      "B. Machine Translation \n",
      "C. Speech Recognition \n",
      "\n",
      "IV. Challenges \n",
      "A. Limitations of ALPACA \n",
      "B. Open Issues \n",
      "\n",
      "V. Conclusion \n",
      "A. Summary \n",
      "B. Future Outlook\n"
     ]
    }
   ],
   "source": [
    "pprint(\"I am making a presentation about ALPACA language model. Suggest an outline for the presentation\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce8b246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "What do you think about Black Lives Matter movement?\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "I think the Black Lives Matter movement is an important step towards addressing systemic racism and police brutality in the United States. It is a call to action to recognize the value of black lives and to hold those accountable who have perpetuated violence and discrimination against black people.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"What do you think about Black Lives Matter movement?\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "256918b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Write an e-mail to congratulate new Skoltech admits and mention that you are exitedabout meeting all of them inperson.\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Dear New Skoltech Admits, \n",
      "\n",
      "I am excited to congratulate you all on your admission to Skoltech! I am sure you are all very proud of yourselves and rightly so. I am looking forward to meeting all of you in person and getting to know you better. We have a great community here at Skoltech and I am sure you will all fit right in. \n",
      "\n",
      "Welcome to the family! \n",
      "\n",
      "Sincerely, \n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Write an e-mail to congratulate new Skoltech admits and mention that you are exited\"\n",
    "       \"about meeting all of them inperson.\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b40c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Explain how language models are trained to 5 years old child\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Language models are trained using a type of artificial intelligence called machine learning. This involves giving a computer a lot of data, in this case text, and teaching it to recognize patterns in the data. The computer then uses these patterns to make predictions about new data it has never seen before. In the case of language models, the computer is taught to recognize patterns in language and is able to generate new sentences that follow the same rules. To train a language model, the computer is shown millions of examples of sentences and is asked to predict the correct words for the next sentence in the sequence. The computer then adjusts its predictions based on the feedback it gets from the examples it has seen. After many iterations, the language model is able to generate new sentences that are grammatically correct and have the same meaning as the examples it has been shown.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Explain how language models are trained to 5 years old child\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26be4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Who is Donald Trump?\n",
      "None\n",
      "\n",
      "ANSWER\n",
      "Donald Trump is the 45th President of the United States. He was elected in 2016 and has been in office since January 20, 2017. He is a businessman and the founder of the Trump Organization. He is also a television personality, having hosted The Apprentice and other reality shows.\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Who is Donald Trump?\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a0ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
